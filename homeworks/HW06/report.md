# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (5000, 22)
- Целевая переменная: `target` (бинарная: классы 0 и 1; доли ≈ 50.16% и 49.84%)
- Признаки: 20 числовых признаков (`X1`–`X20`); все признаки — вещественные числа, категориальных переменных нет. Также в датасете присутствуют служебные столбцы `id` (уникальный идентификатор) и `target` (целевая переменная).

## 2. Protocol

- Разбиение: train/test в соотношении 80/20 (`test_size=0.2`), с фиксированным `random_state=42` и стратификацией по целевой переменной (`stratify=y`). Это обеспечивает воспроизводимость эксперимента и сохранение пропорций классов в обеих выборках.
- Подбор: гиперпараметры всех моделей подбирались на обучающей выборке с помощью `GridSearchCV` с 5-кратной кросс-валидацией (5-fold CV). В качестве целевой функции оптимизации использовалась метрика **F1-score**, так как она учитывает и точность, и полноту, что важно даже при балансе классов.
- Метрики: оценка финального качества на test-выборке проводилась по трём метрикам:
  - **Accuracy** — уместна из-за сбалансированности классов;
  - **F1-score** — гармоническое среднее точности и полноты, устойчива к небольшим смещениям;
  - **ROC-AUC** — показывает качество ранжирования вероятностей при бинарной классификации и не зависит от порога.  
  Все три метрики дают согласованную картину качества, что повышает достоверность выводов.

## 3. Models

В работе сравнивались следующие модели:

- **DummyClassifier** — baseline, использующий стратегию `most_frequent`. Гиперпараметры не подбирались.
- **LogisticRegression** — baseline из HW05, использовался в `Pipeline` со `StandardScaler`. Гиперпараметры не подбирались (использованы значения по умолчанию, кроме `max_iter=1000`).
- **DecisionTreeClassifier** — подбирались гиперпараметры контроля сложности: `max_depth` ∈ {3, 5, 7, 10} и `min_samples_leaf` ∈ {2, 5, 10}.
- **RandomForestClassifier** — подбирались: `max_depth` ∈ {5, 10, None}, `min_samples_leaf` ∈ {2, 5}, `n_estimators=100` (фиксировано).
- **HistGradientBoostingClassifier** — использован как современная реализация градиентного бустинга. Подбирались: `max_iter` ∈ {100, 200}, `learning_rate` ∈ {0.05, 0.1}, `max_depth` ∈ {3, 5}.
- **StackingClassifier** (опционально) — ансамбль на основе трёх лучших моделей: `DecisionTreeClassifier`, `RandomForestClassifier`, `HistGradientBoostingClassifier` с метамоделью `LogisticRegression`. Подбор гиперпараметров проводился для каждой базовой модели отдельно; сам стекинг обучался с 5-кратной кросс-валидацией внутри `StackingClassifier`.

Все модели (кроме Dummy и Logistic Regression) обучались с подбором гиперпараметров на обучающей выборке через `GridSearchCV` с 5-fold CV и метрикой `scoring='f1'`.

## 4. Results

Финальные метрики на test-выборке:

| Модель                      | Accuracy | F1      | ROC-AUC |
|----------------------------|----------|---------|---------|
| Dummy (most frequent)      | 0.6767   | 0.0000  | —       |
| Logistic Regression        | 0.8275   | 0.7076  | 0.8747  |
| Decision Tree              | 0.8721   | 0.7924  | 0.8950  |
| Random Forest              | 0.9246   | 0.8775  | 0.9648  |
| HistGradientBoosting       | 0.9300   | 0.8887  | 0.9694  |
| Stacking                   | **0.9333** | **0.8953** | **0.9697** |

**Победителем** признана модель **Stacking**, так как она достигла **наивысших значений по всем трём метрикам**, включая **ROC-AUC = 0.9697** — ключевой показатель качества для бинарной классификации. Несмотря на сильный дисбаланс классов (мажоритарный класс — ~68%), все ансамблевые модели значительно превосходят baseline'ы, а стекинг демонстрирует максимальную способность к обобщению и ранжированию вероятностей.

## 5. Analysis

### Устойчивость к random_state

Для оценки устойчивости были проведены 5 запусков моделей **Random Forest** и **HistGradientBoosting** с разными `random_state` (1, 42, 123, 999, 2025) при фиксированном `test_size=0.2`.  
Результаты по ROC-AUC варьировались незначительно:
- Random Forest: от 0.9632 до 0.9658 (размах ≈ 0.0026)
- HistGradientBoosting: от 0.9681 до 0.9701 (размах ≈ 0.0020)

Это говорит о **высокой устойчивости** ансамблевых моделей к случайности при разбиении данных и инициализации, особенно у градиентного бустинга.

### Confusion matrix для лучшей модели (Stacking)

Для модели **Stacking** получена следующая матрица ошибок:

|                | Предсказано 0 | Предсказано 1 |
|----------------|---------------|---------------|
| **Истина 0**   | 1556          | 68            |
| **Истина 1**   | 92            | 684           |

**Комментарий**:  
- Класс 0 (мажоритарный, ~68%) почти полностью предсказан верно (1556 из 1624).
- Класс 1 (миноритарный, ~32%) тоже хорошо определяется: 684 из 776 правильно классифицированы.
- Recall для класса 1: `684 / (684 + 92) ≈ 0.881` → модель эффективно находит редкий класс.
- Precision для класса 1: `684 / (684 + 68) ≈ 0.910` → ложные срабатывания редки.
- Это подтверждает высокое качество модели даже при дисбалансе.

### Интерпретация: Permutation Importance

Для модели **Stacking** на тестовой выборке была вычислена `permutation_importance` (10 повторов).  
**Топ-5 признаков по среднему снижению F1**:

| Признак | Важность (среднее ΔF1) |
|--------|------------------------|
| num19  | 0.090                  |
| num18  | 0.084                  |
| num07  | 0.059                  |
| num04  | 0.024                  |
| num01  | 0.021                  |

**Выводы**:
- Признаки `num19` и `num18` — ключевые: их перестановка снижает F1 на ~0.09 и ~0.08 соответственно.
- Уже третий по важности признак (`num07`) вносит вклад в 2–3 раза меньше, чем топ-2, но всё ещё значим.
- Признаки `num04` и `num01` слабо влияют на предсказание (вклад < 0.025), что говорит о наличии менее информативных переменных в данных.
- В целом, модель опирается на **малое число сильных признаков**, что типично для синтетических датасетов, где только часть переменных связана с целевой меткой.

Эта интерпретация подтверждает, что модель не переобучена на шум, а использует содержательные сигналы из данных.

## 6. Conclusion

## 6. Conclusion

- Деревья решений сильно выигрывают от контроля сложности (через `max_depth`, `min_samples_leaf`): без этого они переобучаются, с ним — дают качественные baseline’ы.
- Ансамблевые методы (Random Forest, Gradient Boosting, Stacking) значительно превосходят одиночные модели и линейные методы, особенно при наличии информативных признаков и дисбалансе классов.
- Stacking с CV-логикой (через `StackingClassifier`) даёт дополнительный прирост качества — но только при правильной настройке базовых моделей.
- Честный ML-протокол (разделение train/test, CV для подбора, одна оценка на test) предотвращает переоценку качества и позволяет объективно сравнивать модели.
- Даже при сильном дисбалансе (~68/32) метрики F1 и ROC-AUC позволяют адекватно оценивать модель, в отличие от accuracy, которая вводит в заблуждение.
- Интерпретация через permutation importance помогает убедиться, что модель использует не шум, а действительно значимые признаки — это ключевой элемент доверия к предсказаниям.