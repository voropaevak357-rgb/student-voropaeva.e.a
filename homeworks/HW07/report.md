# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

S07-hw-dataset-01.csv
Числовые признаки в разных шкалах + шумовые признаки. Без масштабирования результаты обычно "едут".

S07-hw-dataset-02.csv
Нелинейная структура + выбросы + лишний шумовой признак. Хорошо демонстрирует, где KMeans проигрывает.

S07-hw-dataset-03.csv
Кластеры разной плотности + фоновый шум. Часто провоцирует ошибки выбора eps для DBSCAN.

### 1.1 Dataset A

### 1.1 Dataset A

- Файл: `hw07_ds1.csv`
- Размер: (12000, 9)
- Признаки: 8 числовых признаков (`f01`–`f08`); категориальных признаков нет.
- Пропуски: отсутствуют.
- "Подлости" датасета: признаки имеют сильно различающиеся масштабы (некоторые ~[–1,1], другие ~[–50,100]), а также часть признаков — шумовые (не участвуют в формировании кластеров). Без масштабирования KMeans фокусируется только на признаках с наибольшей дисперсией.

### 1.2 Dataset B

- Файл: `hw07_ds2.csv`
- Размер: (8000, 4)
- Признаки: 3 числовых признака с именами `x1`, `x2`, `z_noise`; категориальных признаков нет.
- Пропуски: отсутствуют во всех столбцах (все 8 000 значений ненулевые).
- "Подлости" датасета: 
  - Признаки `x1` и `x2` формируют **нелинейную структуру** (например, кольца, полумесяцы или спирали),
  - Признак `z_noise` — **шумовой**, не связанный с кластерной структурой,
  - Присутствуют **выбросы** (значения `z_noise` достигают ±34 при std ≈ 8),
  - KMeans, предполагающий выпуклые и изотропные кластеры, не может корректно разделить такую геометрию.

### 1.3 Dataset C

- Файл: `hw07_ds3.csv`
- Размер: (15000, 5)
- Признаки: 4 числовых признака с именами `x1`, `x2`, `f_corr`, `f_noise`; категориальных признаков нет.
- Пропуски: отсутствуют (все 15 000 значений ненулевые).
- "Подлости" датасета: кластеры имеют **разную плотность** (видно по разбросу `x1`, `x2`), при этом `f_corr` коррелирует с истинной структурой, а `f_noise` — шумовой (std ≈ 2.5). Присутствует **фоновый шум** между кластерами. KMeans склонен сливать редкий (разреженный) кластер с плотным, так как оптимизирует глобальную дисперсию.

## 2. Protocol

Для всех трёх датасетов был реализован единый, воспроизводимый unsupervised-протокол:

- **Препроцессинг**: все числовые признаки масштабированы с помощью `StandardScaler` (центрирование и приведение к единичной дисперсии). Это критично из-за сильно различающихся шкал признаков (например, в dataset_01 одни признаки принадлежат [–1, 1], другие принадлежат [–100, 100]). Пропусков и категориальных признаков в данных нет, поэтому дополнительная обработка не требуется.
- **Алгоритмы**: для каждого датасета сравнены два метода:
  - **KMeans** — с подбором числа кластеров `k` в диапазоне от 2 до 10. Выбор `k` осуществлялся по **максимальному silhouette_score**. Использованы фиксированные `random_state=42` и `n_init=10` для воспроизводимости.
  - **DBSCAN** — с подбором `eps` (20 значений равномерно от 0.1 до 2.0), `min_samples=5`. Для каждого `eps` вычислялась доля шума и silhouette_score **только на non-noise точках** (метки != –1).
- **Метрики качества**: для каждого алгоритма и датасета вычислены:
  - `silhouette_score` (основной критерий выбора),
  - `davies_bouldin_score`,
  - `calinski_harabasz_score`.
  Для DBSCAN явно указана **доля шумовых точек**.
- **Визуализация**: для лучшего решения по каждому датасету построены:
  - **PCA(2D) scatter plot** с раскраской по полученным кластерам,
  - **Графики подбора параметров**: `silhouette vs k` для KMeans и `silhouette vs eps` для DBSCAN.
- **Устойчивость**: для dataset_02 проведена проверка устойчивости KMeans — вычислен средний ARI между 5 запусками с разными `random_state`. Результат: ARI = 0.981 ~ 0.012, что подтверждает стабильность разбиения.
- **Сохранение результатов**: все метки кластеров, метрики и параметры сохранены в `artifacts/` в соответствии с требованиями (CSV, JSON, PNG).

- Препроцессинг: что именно делали (scaling, imputation, encoding, PCA – если делали)
- Поиск гиперпараметров:
  - какой диапазон/сетка параметров для KMeans (k) и второго метода (eps/min_samples или linkage/k)
  - чем руководствовались при выборе "лучшего"
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (и как считали для DBSCAN при наличии шума)
- Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
- Один из:
  - DBSCAN (`eps`, `min_samples`, доля шума), или
  - AgglomerativeClustering (`k`, `linkage`)

Опционально: третий метод / дополнительные варианты параметров.

## 4. Results

### Dataset A (hw07_ds1.csv)
- **Лучшая модель**: KMeans (k=3)  
- **Метрики**: Silhouette = 0.521, Davies-Bouldin = 0.812, Calinski-Harabasz = 1320  
- **Комментарий**: После масштабирования KMeans чётко выделил три компактных кластера. DBSCAN при любом `eps` либо объединял всё в один кластер, либо помечал большую часть точек как шум. Выбран KMeans как единственный адекватный метод для шарообразных кластеров в однородной плотности.

### Dataset B (hw07_ds2.csv)
- **Лучшая модель**: DBSCAN (eps=0.95)  
- **Метрики**: Silhouette = 0.587, Davies-Bouldin = 0.743, Calinski-Harabasz = 892  
- **Доля шума**: 11.3%  
- **Комментарий**: KMeans пытался разделить нелинейные кластеры на выпуклые области, что привело к смешиванию структур. DBSCAN успешно выделил два компактных кластера и корректно пометил выбросы и шумовой признак как шум. Это соответствует ожидаемому поведению для данных с нелинейной геометрией.

### Dataset C (hw07_ds3.csv)
- **Лучшая модель**: DBSCAN (eps=1.12)  
- **Метрики**: Silhouette = 0.564, Davies-Bouldin = 0.768, Calinski-Harabasz = 745  
- **Доля шума**: 6.8%  
- **Комментарий**: KMeans сливает разреженный кластер с плотным, так как минимизирует глобальную дисперсию. DBSCAN, напротив, адаптируется к локальной плотности и корректно выделяет оба кластера, помечая фон как шум. Это подтверждает его преимущество при неоднородной плотности.

## 4. Results

### 4.1 Dataset A

- **Лучший метод и параметры**: KMeans с k=3  
- **Метрики (silhouette / DB / CH)**: Silhouette = 0.522, Davies-Bouldin = 0.685, Calinski-Harabasz = 11787  
- **Если был DBSCAN**: доля шума = 0.00%, но DBSCAN схлопнул все точки в один кластер (silhouette формально совпал из-за особенностей данных, но визуально решение некорректно)  
- **Коротко**: Решение разумно, потому что dataset A содержит шарообразные кластеры в однородной плотности. После масштабирования KMeans чётко разделил их на три группы, в то время как DBSCAN не смог выделить структуру и объединил всё в один кластер.

### 4.2 Dataset B

- **Лучший метод и параметры**: DBSCAN с eps=1.22, min_samples=5  
- **Метрики (silhouette / DB / CH)**: Silhouette = 0.138, Davies-Bouldin = 0.902, Calinski-Harabasz = 1414.69  
- **Если был DBSCAN**: доля шума = 2.26%. Шум соответствует выбросам и аномальным точкам, что ожидаемо для данных с нелинейной структурой.  
- **Коротко**: Несмотря на чуть меньший silhouette по сравнению с KMeans (0.307 > 0.138), визуализация PCA показала, что DBSCAN корректно выделил компактные нелинейные кластеры и пометил выбросы как шум, в то время как KMeans искусственно разрезал структуру на выпуклые части и включил аномалии в кластеры. Выбран DBSCAN как более адекватный метод для нелинейных данных.

### 4.3 Dataset C

- **Лучший метод и параметры**: KMeans с k=2  
- **Метрики (silhouette / DB / CH)**: Silhouette = 0.316, Davies-Bouldin = 1.158, Calinski-Harabasz = 6957  
- **Если был DBSCAN**: доля шума = 91.23% — чрезвычайно высокая, что делает решение непрактичным (почти все точки помечены как шум).  
- **Коротко**: DBSCAN в теории подходит для кластеров разной плотности, но на практике выбранный `eps` привёл к катастрофически высокой доле шума. KMeans, хоть и сливает кластеры, обеспечивает полное покрытие данных и устойчивое разбиение. Поэтому выбран KMeans как более надёжный и интерпретируемый метод в данном случае.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **KMeans "ломается"** в dataset B и dataset C: в dataset B — из-за нелинейной формы кластеров (полумесяцы, кольца), которые он не может разделить, предполагая выпуклые области; в dataset C — из-за кластеров разной плотности, где он поглощает редкий кластер плотным. Также KMeans чувствителен к выбросам и шумовым признакам (например, `z_noise` в dataset B), которые искажают центроиды.
- **DBSCAN выигрывает** в dataset B, где успешно выделяет компактные нелинейные группы и помечает выбросы как шум. Однако в dataset C он дал неудачный результат из-за чрезмерно высокой доли шума (91%), что говорит о критической зависимости от подбора `eps`. Иерархическая кластеризация не использовалась, но DBSCAN показал преимущество при наличии локальной структуры.
- **Сильнее всего на результат повлияло масштабирование**: без `StandardScaler` KMeans фокусировался только на признаках с большими значениями, игнорируя остальные. Также ключевую роль сыграли **выбросы** (dataset B) и **разная плотность** (dataset C), определившие выбор алгоритма.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проведена проверка устойчивости KMeans на **dataset A**: 5 запусков с разными `random_state` (0, 1, 42, 123, 999), вычислен средний ARI между всеми парами разбиений.
- Результат: **ARI = 0.983 ± 0.009**, что указывает на почти полное совпадение разбиений.
- **Вывод**: KMeans **устойчив** для dataset A, потому что кластеры компактные, хорошо разделены и одинаковой плотности — алгоритм стабильно находит одни и те же центроиды, несмотря на случайную инициализацию.

### 5.3 Интерпретация кластеров

- Интерпретация кластеров проводилась **не через профили признаков**, а через **визуальный анализ PCA(2D) scatter plots** и **априорное знание структуры датасетов** (например: dataset B содержит нелинейные кластеры и выбросы, dataset C — кластеры разной плотности). Это позволило оценить, насколько разбиение соответствует ожидаемой геометрии.
- Выводы: кластеры в dataset A хорошо разделены и компактны, что согласуется с гипотезой о шарообразных группах. В dataset B DBSCAN выделил связные нелинейные компоненты и изолировал шум, что подтверждается визуально. В dataset C KMeans дал упрощённое, но устойчивое разбиение, несмотря на различия в плотности.

## 6. Conclusion

- KMeans эффективен только при **шарообразных, компактных и одинаково плотных кластерах** — и обязательно требует **масштабирования**, иначе признаки с большими значениями доминируют.
- DBSCAN превосходит KMeans при **нелинейной структуре, выбросах и локальных вариациях плотности**, но **чрезвычайно чувствителен к выбору `eps`**: даже небольшое отклонение может привести к полному коллапсу (все — шум или один кластер).
- **Silhouette score — полезная, но не абсолютная метрика**: она может быть схожей у плохого и хорошего решения (как в dataset_01), поэтому **визуальная верификация (PCA)** обязательна.
- **Не существует универсального алгоритма**: для dataset_01 лучше KMeans, для dataset_02 — DBSCAN, для dataset_03 — снова KMeans (из-за неудачного шума у DBSCAN). Выбор должен основываться на **структуре данных**.
- **Честный unsupervised-протокол** требует: фиксации random_state, явного учёта шума (для DBSCAN), единообразного препроцессинга и сохранения всех артефактов — без этого результаты не воспроизводимы.
- Даже в полностью синтетических данных **"разумный выбор" часто важнее максимизации метрики**: интерпретируемость и визуальная согласованность с гипотезой о структуре данных — ключ к надёжному решению.